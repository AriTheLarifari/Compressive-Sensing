\documentclass[11pt]{beamer}
\usetheme{Madrid}
\usefonttheme{serif}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tcolorbox}
\tcbuselibrary{theorems, breakable,}
\tcbuselibrary{skins}



\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!40!black}
\colorlet{mypurple}{red!50!blue!90!black!80}
\colorlet{mydarkred}{myred!80!black}
\colorlet{mydarkblue}{myblue!80!black}
\colorlet{mymagenta}{magenta}
\colorlet{xcol}{blue!60!black}
\colorlet{Defcol}{red!5}
\colorlet{Satzcol}{blue!90!black!80!cyan!10!white}
\colorlet{Korcol}{blue!10!white}
\colorlet{Axcol}{purple!10!white}
\colorlet{Bemcol}{black!2!white}
\colorlet{Motcol}{cyan!10!white}
\colorlet{Bspcol}{green!50!olive!2!white}
\colorlet{Bewcol}{yellow!5!white}

\newcounter{my}[section]
\def\themytheorem{\thesection.\arabic{my}}

\tcbset{
thmstyle/.style={enhanced, breakable, attach boxed title to top left={yshift=-0.9mm,xshift=2.5mm}, boxrule=0.15mm, boxed title style={boxrule=0.15mm}, fonttitle=\itshape\bfseries},
bewstyle/.style={skin=enhanced, parbox=false,boxrule=0.15mm,leftrule=0.5mm,rightrule=0.15mm, coltitle=black, breakable, fonttitle=\itshape},
bemstyle/.style={skin=enhanced, parbox=false,boxrule=0.15mm,leftrule=0.5mm,rightrule=0.15mm, coltitle=black, breakable, fonttitle=\itshape\bfseries},
}

 \newtcbtheorem[auto counter, number within= section]{Def}{Definition}{thmstyle,colback=Defcol,colframe=red!55!black!98!white,colbacktitle=red!75!black!30!pink}{Def}
 
\newtcbtheorem[use counter from= Def]{Satzz}{Theorem}{thmstyle,colback=Satzcol, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{Satz}

\newtcbtheorem[use counter from= Def]{Lemmaa}{Lemma}{thmstyle,colback=Satzcol, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{Lemma}

 \newtcbtheorem[use counter from= Def]{Prop}{Proposition}{thmstyle,colback=Satzcol, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{Prop}
 
 \newtcbtheorem[use counter from= Def]{Kor}{Corollary}{thmstyle,colback=Korcol, colframe=blue!30!black,colbacktitle=blue!40!white}{Kor}
 
 \newtcbtheorem[use counter from= Def]{Ax}{Axiom}{thmstyle,colback=Axcol, colframe=purple!30!black,colbacktitle=purple!40!white}{Ax}
 
\newtcbtheorem[use counter from= Def]{Bemerkung}{Remark}{bemstyle,colback=Bemcol, colframe=white!30!black,colbacktitle=black!5!white}{Bem}

\newtcbtheorem[use counter from= Def]{Notation}{Notation}{bemstyle,colback=Bemcol, colframe=white!30!black,colbacktitle=white}{Notation}

\newtcbtheorem[use counter from= Def]{Motivation}{Motivation}{thmstyle,colback=Motcol, colframe=cyan!30!black,colbacktitle=cyan!40!white}{Mot}




%\newtcolorbox[use counter from= Def]{Bemerkung}{breakable, empty, coltitle=black, title=\textbf{Bemerkung.}}
%\newtbctheorem[use counter from= Def]{Bemerkung}{Bemerkung}{thmstyle,colback=cyan!10!white, colframe=cyan!30!black,colbacktitle=cyan!40!white}{Bemerkung}



\newtcolorbox{Formel}{bewstyle,colback=blue!90!black!80!cyan!10!white, colframe=blue!30!black,colbacktitle=blue!90!black!80!cyan!10!white,}

% \tcbmaketheorem{Def}{Definition}{thmstyle, colback=red!5,colframe=red!55!black!98!white,colbacktitle=red!75!black!30!pink}{my}{def}

% \tcbmaketheorem{Satz}{Satz}{thmstyle,colback=blue!90!black!80!cyan!10!white, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{my}{thm}

% \tcbmaketheorem{Lemma}{Lemma}{thmstyle,colback=blue!90!black!80!cyan!10!white, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{my}{lemma}

% \tcbmaketheorem{Prop}{Proposition}{thmstyle,colback=blue!90!black!80!cyan!10!white, colframe=blue!80!black!99!cyan,colbacktitle=blue!85!black!80!cyan!60!white,}{my}{prop}

% \tcbmaketheorem{Kor}{Korollar}{thmstyle,colback=blue!10!white, colframe=blue!30!black,colbacktitle=blue!40!white}{my}{kor}

% \tcbmaketheorem{Beispiel}{Beispiel}{bewstyle,colback=green!10!white!97!olive, colframe=green!65!olive,colbacktitle=green!10!white!97!olive, title=\textbf{Beispiel.}}{my}{bsp}


\DeclareMathOperator{\sen}{sen}
\DeclareMathOperator{\tg}{tg}

\setbeamertemplate{caption}[numbered]

\author[Autor]{Arianna Rast}
\title{Basis pursuit II}
\newcommand{\email}{email}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\KK}{\mathbb{K}}
\renewcommand{\emph}{\textbf}
\newcommand{\pp}{\partial}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\p}[2]{\left\langle #1,#2\right\rangle}
\newcommand{\supp}{\text{supp}}
\newcommand{\I}{\mathrm{i}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\RR}{\mathbb R}
\newcommand{\cone}{\mathrm{cone}}
%\setbeamercovered{transparent} 
\setbeamertemplate{navigation symbols}{} 

\institute[]{LMU Munich} 
\date{\today} 
%\subject{}

% ---------------------------------------------------------
% Selecione um estilo de referência
\bibliographystyle{apalike}

%\bibliographystyle{abbrv}
%\setbeamertemplate{bibliography item}{\insertbiblabel}
% ---------------------------------------------------------

% ---------------------------------------------------------
% Incluir os slides nos quais as referências foram citadas
%\usepackage[brazilian,hyperpageref]{backref}

%\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
%\renewcommand{\backref}{}
%\renewcommand*{\backrefalt}[4]{
%	\ifcase #1 %
%		Nenhuma citação no texto.%
%	\or
%		Citado na página #2.%
%	\else
%		Citado #1 vezes nas páginas #2.%
%	\fi}%
% ---------------------------------------------------------

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Summary}
\tableofcontents 
\end{frame}

\begin{frame}{Review Exact Reconstruction}
\begin{itemize}
	\item For \(A\in \KK^{m\times N}\) and \(s\in \NN\) we have that
	\begin{align*}
	\left.\begin{array}{c}
		\forall x\in \CC^N\,s\text{-sparse}:\\
		x\text{ is the unique minimizer} \\  \text{of }
		\left\{\|z\|_1\,\big|\, Az=Ax\right\}
	\end{array}\right\}
\iff  A\text{ satisfies the NSP of order }s.
\end{align*}
\item Also, 
\[\left.\begin{array}{c}
		\forall x\in \CC^N\,s\text{-sparse}:\\
		x\text{ is the unique minimizer} \\  \text{of }
		\left\{\|z\|_1\,\big|\, Az=Ax\right\}
	\end{array}\right\} \iff \left\{\begin{array}{c}
		\forall x\in \CC^N\,s\text{-sparse}:\\
		\arg\min\left\{\|z\|_1\,\big|\,Az=Ax\right\}\\
		=\arg\min\left\{\|z\|_0\,\big|\,Az=Ax\right\}
	\end{array}\right.
\]
\textcolor{red}{Stimmt die Rueckrichtung auch?}
Hence, the NSP of order \(s\) is a necessary and sufficient condition for the exact reconstruction of every \(s\)-sparse vector via the basis pursuit.
\end{itemize}
\end{frame}

\begin{frame}{Review Stability}
	\begin{itemize}
		\item The basis pursuit is stable under a sparsity defect in the vector \(x\), if the measurement matrix satisfies the stable null space property (SNSP).
		\item For a matrix \(A\in\CC^{m\times N}\), we have
\[\left.\begin{array}{c}
\forall x,z\in \CC^N:\\
\|z-x\|_1\le \frac{1+\rho}{1-\rho}\left(\|z\|_1-\|x\|_1+2\|x_{\overline{S}}\|_1\right)
\end{array}\right\}
\iff 
\begin{array}{c}
A\text{ satisfies}\\
\text{SNSP}(\rho,S)
\end{array}
\,.\]
\item In particular, if \(A\) satisfies the SNSP($\rho,S$), any minimizer \(x^{\#}\) of \(\left\{\|z\|_1\,\big|\,Ax=Az\right\}\) satisfies 
\[\|x-x^{\#}\|_1\le \frac{2(1+\rho)}{1-\rho}\sigma_s(x)_1\,.\]
	\end{itemize}
\end{frame}

\section{Robustness}

\begin{frame}{Robustness}
In this chapter we also want to handle noise in the measurement in addition to a sparsity deficit of the data.\\
 What additional assumptions do we need to obtain similar results, if we consider the problem
 \[\min\left\{\|z\|_1\,\big|\,z\in \CC^N,\;\;\|Az-y\|\le \eta\right\}\,?\tag{$P_{1,\eta}$}\]
 It depends on the norm, in which we measure the error, i.e. the distance of TODO
\end{frame}


\begin{frame}{}

    At first, we consider the situation where we measure the noise in the \(\ell^1\)-norm, i.e. \(\|Az-y\|=\|Az-y\|_1\).
    \begin{Def}
    {Robust null space property}{} A matrix \(A\in\CC^{m\times N}\) is said to satisfy the \emph{robust null space property} with respect to \(\|\cdot\|\) with the constants \(\rho\in (0,1)\) and \(\tau>0\) relative to a set \(S\subseteq[N]\) iff
    \[\forall v\in \CC^N:\;\; \|v_S\|_1\le \rho\|v_{\overline S}\|_1+\tau \|Av\|\,.\tag{RNSP($\|\cdot\|,\rho,\tau,S$)}\]
    \(A \) satisfies the robust null space property of \emph{order} \(s\) with respect to \(\|\cdot\|\) with the constants \(\rho\in (0,1)\) and \(\tau>0\) RNSP(\(\|\cdot\|,\rho,\tau, s\)) iff \(A \) satisfies RNSP(\(\|\cdot\|,\rho,\tau,S\)) for all sets \(S\subseteq[N]\) with \(|S|\le s\).
    \end{Def}
    \textcolor{red}{Intuition for the null space property? Is it a common property or rather rare? Is it true, that it is relatively hard to verify?}
\end{frame}

\begin{frame}
	\begin{itemize}
		\item Maybe the content of this slide is just done on the board.
		\item Note that RNSP($\|\cdot\|,\rho,0,S$)$\iff$SNSP($\rho,S$) for all \(\|\cdot\|\), \(\rho\) and \(S\).
		\item Furthermore, RNSP($\|\cdot\|,\rho,\tau,S$)$\implies$ SNSP($\rho,S$) for all \(\|\cdot\|\), \(\rho\), \(\tau\) and \(S\).
\item Hence, all statements are in particular statements on SNSP
	\end{itemize}
\end{frame}

\begin{frame}{}
    The main result is the following theorem.
    \begin{Satzz}
    {}{}
    A matrix \(A\in\CC^{m\times N}\) satisfies RNSP(\(\|\cdot\|,\rho,\tau,S\)) if and only if 
    \begin{align*}
    &\forall x,z\in \CC^N:\\ &\|z-x\|_1\le \frac{1+\rho}{1-\rho}(\|z\|_1-\|x\|_1+2\|x_S\|)+\frac{2\tau}{1-\rho}\|A(x-z)\|\,.
    \end{align*}
    \end{Satzz}
    This is a generalisation of the previously discussed theorem for the SNSP.

\end{frame}

\begin{frame}{}
Before proving this theorem, note the following corollary.
    \begin{Kor}
        {}{}
        Assume that \(A\in\CC^{m\times N}\) satisfies RNSP(\(\|\cdot\|,\rho,\tau,s\)) with \(0<\rho<1\) and \(\tau>0\) and let \(x\in \CC^N\). Then, if
        \[\mathcal L_{x,\eta}:
        =\pp B_{\min\{\|z_1\|\,|\,\|Ax-Az\|\le \eta\}}^{\|\cdot\|_1}(0)\cap A^{-1}(Ax)
        \]
        is the solution set of the problem ($P_{1,\eta}$) with \(y=Ax\), then 
        \[\sup_{x^{\#}\in \mathcal L_x}\|x-x^{\#}\|_1\le \frac{2(1+\rho)}{1-\rho}\sigma_s(x)_1+\frac{4\tau}{1-\rho}\eta\,,\]
        i.e. the solution set \(\mathcal L_x\) is contained in a ball of radius \(\frac{2(1+\rho)}{1-\rho}\sigma_s(x)_1+\frac{4\tau}{1-\rho}\eta\) around \(x\) in the \(\ell^1\)-norm.
    \end{Kor}
    \textcolor{red}{Macht es Sinn, dazu ein Bild zu malen?}
\end{frame}

\begin{frame}{}
    \begin{itemize}
    	\item The content of this slide might be done only on the board.
    	\item Explanation why the corollary follows from the theorem.
    	\item Proof of the theorem (maybe shifted to the second part of the presentation, since similar to last time).
    \end{itemize}
\end{frame}

\begin{frame}{}
\begin{itemize}
	\item Since \(\|\cdot\|_p\le \|\cdot\|_q\) for \(p\le q\), it is harder to bound the \(\ell^q\)-error from above than the \(\ell^p\) error for \(p\le q\). 
	\item  Of course, the norms are equivalent, but the constant for the other direction depends on the dimension, which we assume is large.
	\item But if we assume an adapted, stronger version of the RNSP, we get a useful bound for the error.
\end{itemize}
\end{frame}

\begin{frame}{}
 \begin{Def}
 {$\ell^q$-robust null space property}{}
 Let \(q\ge 1\). A matrix \(A\in \CC^{m\times N}\) satisfies the \emph{$\ell^q$-robust null space property} of \emph{order} \(s\in \NN\) (with respect to \(\|\cdot\|\)) with the constants \(\rho\\in (0,1)\) and \(\tau\ge0\) iff
 \[TODO\]
 \textcolor{red}{Warum tau echt groesser 0?}
 \end{Def}
 \end{frame}

\section{Recovery of individual vectors}
\begin{frame}{Recoverz of individual vectors}
    So far, our problem was to reconstruct \(x\) from the information what \(Ax\) is and that \(x\) is sparse (or knowing the support of \(x\)). We saw that the convex relaxation of the corresponding minimization problem reconstructs the minimizer iff the null space property holds for \(A\). What, if we have additional a priori information on \(x\)? Maybe then there is a way to solve it in an acceptable computational complexity? But this is not discussed here, we still consider the convex relaxation, but now assume conditions on \(A\) and \(x\). \textcolor{red}{What does finer mean?}
\end{frame}

\begin{frame}
\begin{itemize}
	\item As we will see, there is a difference between the real and complex case.
	\item Some other remarks.
\end{itemize}

\end{frame}

\begin{frame}
	\begin{Satzz}
		{}{} Let \(A\in\CC^{m\times N}\) and \(x\in\CC^N\) with support \(S\subseteq[N]\) be given. Then, the following conditions are equivalent:
		\begin{itemize}
			\item[(i)] \(\forall v\in \ker(A)\setminus\{0\}:\;\;|\p{v}{\sgn(x)}|< \|v_{\overline S}\|_1\).
			\item[(ii)] \(A_S\) is injective and 
			\[\exists h\in \CC^m:\;\;\left\{\begin{array}{cl}
				(A^*h)_j=\sgn(x_j),&j\in S\;\;\;\text{i.e. }A^*_Sh=\sgn(x_S)\\
				(A^*h)_j<1,&j\in \overline S
			\end{array}\right.\,.\]
			\end{itemize}
			If one (and hence both) of these conditions hold, then \(x\) is the unique minimizer of the problem
			\[\min\left\{\|z\|_1\,\big|\,Az=Ax\right\}\,.\]
	\end{Satzz}
	
\end{frame}

\begin{frame}{Remarks}
	\begin{itemize}
		\item \(A\text{ satisfies the NSP relative }S\iff \forall x\in \CC^N \text{ with }\supp(x)\subseteq S:\text{ (a) holds}.\)
		\item If (a) holds for \(x\in \CC^N \) with \(\supp(x)\subseteq S\), (a) also holds for all 
		\[\{x'\in \CC^N\,|\, \supp (x') \subseteq S\text{ and }\sgn(x)_{\supp(x')}=\sgn(x')_{\supp(x')}\}\,.\]
		\item There are stable and robust versions of this theorem, which yield slightly weaker error bounds than of the previous theorems.
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{itemize}
		\item If \(A_S \) is injective, then \(A_S^*A_S\) is invertible.
		\item Furthermore, the Moore-Penrose pseudo-inverse of \(A_S\) is then a left-inverse of \(A_S\) and given by
		\[A_S^{\dagger}=(A_S^*A_S)^{-1}A_S^*\,.\]
		\item Therefore the condition \(A^*_Sh=\sgn(x_S)\) is satisfied by \(h:=(A_S^{\dagger})^*\sgn(x_S)\).
		\item Hence, if this choice of \(h\) also satisfies the rest of (b), then the Theorem holds:
	\end{itemize}
\end{frame}

\begin{frame}
		\begin{Kor}
			{}{}Let \(A=(a_1,\ldots,a_N)\in\CC^{m\times N}\) and \(x\in\CC^N\) with support \(S\subseteq[N]\) be given. If \(A_S\) is injective and if 
			\begin{align*}
			\forall l\in \overline S:\;\;&\left|\p{A_S^{\dagger}a_l}{\sgn(x_S)}\right|=\left|\p{a_l}{(A_S^{\dagger})^*\sgn(x_S)}\right|\\
			&=\left(A^*(A_S^{\dagger})^*\sgn(x_S)\right)_l<1\,,
			\end{align*}
			then \(x\) is the unique minimizer of the problem
			\[\min\left\{\|z\|_1\,\big|\,Az=Ax\right\}\,.\]
		\end{Kor}

\end{frame}

\begin{frame}{The converse direction}
	 The converse of the Theorem 4.26 is not true in general, e.g. take 
		\[ A=\begin{pmatrix}1&0&-1\\0&1&-1\end{pmatrix}, \;\;x=\begin{pmatrix}\e^{-\pi \I/3}\\\e^{\pi \I/3}\\0\end{pmatrix}\,.\]
		The solution space of $Az=Ax$ is then 
		\[\left\{\begin{pmatrix}
		0\\\sqrt 3 \I\\-\e^{-\I \pi/3}
		\end{pmatrix}+z\begin{pmatrix}
		1\\1\\1
		\end{pmatrix}\,\bigg|\, z\in \CC\right\}\,,\]
		and hence, the minimization problem consists in finding the point \(z\in \CC\) such that the sum of the distances to the points \(z_1=0\), \(z_2=-\sqrt 3\I\), \(z_3=\e^{-\I \pi/3}\) is minimal.
\end{frame}

\begin{frame}
	\begin{minipage}{0.35\linewidth}
	\begin{tikzpicture}[scale=1.5]
		\draw[->] (-1,0) -- (1,0) ;
		\draw[->] (0,-2) -- (0,1) ;
		\draw[blue] (0.5,-0.866)node[right, red]{$z_3$}--(0,-sqrt 3);
		\draw[blue] (0.5,-0.866)--(0,0)node[above left,black]{$z_1$};
		\draw[blue] (0,-sqrt 3)node[left, black]{$z_2$}--(0,0);
		\fill (0,0) circle (1.5pt);
		\fill (0,-sqrt 3) circle (1.5pt);
		\fill[red] (0.5,-0.866) circle (1.5pt);
	\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.55\textwidth}
	In the picture one can see that the sum of the distances is minimal exactly for \(z=z_3\) (cf. first Fermat point, the angle at \(z_3\) is \(120^{\circ}\)). Hence, \(x=(0,\sqrt{3}\I, \e^{-\I\pi/3})^T+z_3(1,1,1)^T\) is the unique minimizer of the problem.
\end{minipage}
\vspace{0.5cm}\\
However, the condition (a) does not hold: For \(v=(z,z,z)\in \ker(A)\setminus\{0\}\), we have that
\[|\p{\sgn(x)}{v_{\{1,2\}}}|=|\e^{\pi \I/3}z+\e^{-\pi \I/3}z|=|z|=\|v_{\{3\}}\|_1\,.\]
\end{frame}

\begin{frame}
	In the real case, however, the converse does actually hold:
	\begin{Satzz}
		{}{}
		 Let \(A\in\RR^{m\times N}\) and \(x\in\RR^N\) with support \(S\subseteq[N]\) be given. Then, the following conditions are equivalent:
		\begin{itemize}
			\item[(i)] \(\forall v\in \ker(A)\setminus\{0\}:\;\;|\p{v}{\sgn(x)}|< \|v_{\overline S}\|_1\).
			\item[(ii)] \(A_S\) is injective and 
			\[\exists h\in \RR^m:\;\;\left\{\begin{array}{cl}
				(A^*h)_j=\sgn(x_j),&j\in S\\
				(A^*h)_j<1,&j\in \overline S
			\end{array}\right.\,.\]
			\item[(iii)] \(x \) is the unique minimizer of
			\[\min\left\{\|z\|_1\,\big|\,z\in \RR^N,\;Az=Ax\right\}\,.\]
		\end{itemize}
	\end{Satzz}
\end{frame}

\begin{frame}{}
	%Another way to characterize the exact reconstruction of \(x\) via the basis pursuit involves the following definition:
	\begin{Def}
		{}{} Let \(x\in \RR^N \), then the \emph{tangent cone} to the \(\ell^1\)-ball at \(x\) is defined as
		\[T(x)=\mathrm{cone}\left\{z-x\,|\, z\in \RR^N,\;\|z\|_1\le \|x\|_1=\cone(\overline{B_{\|x\|_1}^{\|\cdot\|_1}(x)})\right\}\,.\]
	\end{Def}
	\vspace{0.5cm}
	\begin{minipage}{0.45\linewidth}
		\centering
	\begin{tikzpicture}[scale=0.5]
		\begin{scope}
			\clip (0,-1) circle (4);
		\fill(0,0) circle (1.5pt);
		\path (0,0) node [below]{$x$};
		\fill[opacity=0.1](1,0)--(0,1)--(-1,0)--(0,-1)--cycle;
		\fill (0,-1) circle (1.5pt);
		\path (0,-1) node [below]{$0$};
		\fill[opacity=0.2] (0,-1)--(4,3)--(0,4)--(-4,3)--cycle;
		\end{scope}
		\end{tikzpicture}
	\end{minipage}
	\begin{minipage}{0.45\linewidth}
		\centering
	\begin{tikzpicture}[scale=0.5]
		\begin{scope}
			\clip (0,-1) circle (4);
		\fill(0,0) circle (1.5pt);
		\path (0,0) node [below]{$x$};
		\fill[opacity=0.1](1,0)--(0,1)--(-1,0)--(0,-1)--cycle;
		\fill (-0.75,-0.25) circle (1.5pt);
		\path (-0.75,-0.25) node [below]{$0$};
		\fill[opacity=0.2] (-4,3)--(4,-5)--(8,-1)--(0,7)--cycle;
		\end{scope}
		\end{tikzpicture}
	\end{minipage}

\end{frame}

\begin{frame}
\begin{Satzz}
	{}{} Let \(A\in \RR^{m\times N }\) and \(x\in \RR^N \). Then
	\[
	\left.\begin{array}{c}

		x\text{ is the unique minimizer} \\  \text{of }
		\left\{\|z\|_1\,\big|\, Az=Ax\right\}
	\end{array}\right\} \iff \ker(A)\cap T(x)=\{0\}\,.
	\]
\end{Satzz}
\end{frame}

\end{document}